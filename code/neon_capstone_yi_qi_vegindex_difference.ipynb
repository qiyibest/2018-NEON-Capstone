{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this code calculates differences of vegetation indices between 2017 and 2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #don't display warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import h5py\n",
    "from skimage import exposure\n",
    "import gdal\n",
    "import os\n",
    "import osr\n",
    "\n",
    "def list_dataset(name,node):\n",
    "    \n",
    "    \"\"\"list_dataset lists the name and location of each dataset stored in an hdf5 file.\n",
    "    --------\n",
    "    See Also:\n",
    "    --------\n",
    "    ls_dataset: \n",
    "        Lists name, shape, and type of each dataset stored in an hdf5 file.\n",
    "    --------\n",
    "    Usage:\n",
    "    --------\n",
    "    f = h5py.File('NEON_D02_SERC_DP3_368000_4306000_reflectance.h5','r') \n",
    "    f.visititems(list_dataset)\"\"\"\n",
    "    \n",
    "    if isinstance(node, h5py.Dataset):\n",
    "        print(name)\n",
    "\n",
    "def ls_dataset(name,node):\n",
    "    \n",
    "    \"\"\"ls_dataset lists the name, shape, and datatype of each dataset stored in \n",
    "    an hdf5 file.\n",
    "    --------\n",
    "    See Also\n",
    "    --------\n",
    "    list_dataset: \n",
    "        Lists name and location of each dataset stored in an hdf5 file\n",
    "    Example:\n",
    "    --------\n",
    "    f = h5py.File('NEON_D02_SERC_DP3_368000_4306000_reflectance.h5','r') \n",
    "    f.visititems(ls_dataset)\"\"\"\n",
    "    \n",
    "    if isinstance(node, h5py.Dataset):\n",
    "        print(node)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will allow us to output GeoTIFF files.\n",
    "def array2raster(newRasterfn,rasterOrigin,pixelWidth,pixelHeight,array,epsg):\n",
    "\n",
    "    cols = array.shape[1]\n",
    "    rows = array.shape[0]\n",
    "    originX = rasterOrigin[0]\n",
    "    originY = rasterOrigin[1]\n",
    "\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    outRaster = driver.Create(newRasterfn, cols, rows, 1, gdal.GDT_Float32)\n",
    "    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))\n",
    "    outband = outRaster.GetRasterBand(1)\n",
    "    outband.WriteArray(array)\n",
    "    outRasterSRS = osr.SpatialReference()\n",
    "    outRasterSRS.ImportFromEPSG(epsg)\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outband.FlushCache()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a functoin that transform raster to array\n",
    "def raster2array(geotif_file):\n",
    "    metadata = {}\n",
    "    dataset = gdal.Open(geotif_file)\n",
    "    metadata['array_rows'] = dataset.RasterYSize\n",
    "    metadata['array_cols'] = dataset.RasterXSize\n",
    "    metadata['bands'] = dataset.RasterCount\n",
    "    metadata['driver'] = dataset.GetDriver().LongName\n",
    "    metadata['projection'] = dataset.GetProjection()\n",
    "    metadata['geotransform'] = dataset.GetGeoTransform()\n",
    "\n",
    "    mapinfo = dataset.GetGeoTransform()\n",
    "    metadata['pixelWidth'] = mapinfo[1]\n",
    "    metadata['pixelHeight'] = mapinfo[5]\n",
    "\n",
    "    metadata['ext_dict'] = {}\n",
    "    metadata['ext_dict']['xMin'] = mapinfo[0]\n",
    "    metadata['ext_dict']['xMax'] = mapinfo[0] + dataset.RasterXSize/mapinfo[1]\n",
    "    metadata['ext_dict']['yMin'] = mapinfo[3] + dataset.RasterYSize/mapinfo[5]\n",
    "    metadata['ext_dict']['yMax'] = mapinfo[3]\n",
    "\n",
    "    metadata['extent'] = (metadata['ext_dict']['xMin'],metadata['ext_dict']['xMax'],\n",
    "                          metadata['ext_dict']['yMin'],metadata['ext_dict']['yMax'])\n",
    "\n",
    "    if metadata['bands'] == 1:\n",
    "        raster = dataset.GetRasterBand(1)\n",
    "        metadata['noDataValue'] = raster.GetNoDataValue()\n",
    "        metadata['scaleFactor'] = raster.GetScale()\n",
    "\n",
    "        # band statistics\n",
    "        metadata['bandstats'] = {} #make a nested dictionary to store band stats in same \n",
    "        stats = raster.GetStatistics(True,True)\n",
    "        metadata['bandstats']['min'] = round(stats[0],2)\n",
    "        metadata['bandstats']['max'] = round(stats[1],2)\n",
    "        metadata['bandstats']['mean'] = round(stats[2],2)\n",
    "        metadata['bandstats']['stdev'] = round(stats[3],2)\n",
    "\n",
    "        array = dataset.GetRasterBand(1).ReadAsArray(0,0,metadata['array_cols'],metadata['array_rows']).astype(np.float)\n",
    "        array[array==int(metadata['noDataValue'])]=np.nan\n",
    "        array = array/metadata['scaleFactor']\n",
    "        return array, metadata\n",
    "\n",
    "    elif metadata['bands'] > 1:\n",
    "        print('More than one band ... need to modify function for case of multiple bands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, fnmatch\n",
    "listOfFiles_2017 = os.listdir('../../Data/capstone/2017/NEON_D17_SJER_DP3_258000_4108000_VegIndices/')  \n",
    "listOfFiles_2018 = os.listdir('../../Data/capstone/2018/NEON_D17_SJER_DP3_258000_4108000_VegIndices/')  \n",
    "pattern = \"*.tif\"  \n",
    "\n",
    "\n",
    "for entry_2017 in listOfFiles_2017:\n",
    "    if fnmatch.fnmatch(entry_2017, pattern):\n",
    "        for entry_2018 in listOfFiles_2018:\n",
    "            if fnmatch.fnmatch(entry_2017,entry_2018):\n",
    "                print ('../../Data/capstone/2017/NEON_D17_SJER_DP3_258000_4108000_VegIndices/'+entry_2017)\n",
    "                print ('../../Data/capstone/2018/NEON_D17_SJER_DP3_258000_4108000_VegIndices/'+entry_2018)\n",
    "                # read in the corresponding 2017 and 2018 indices\n",
    "                index_2017, index_2017_md = raster2array('../../Data/capstone/2017/NEON_D17_SJER_DP3_258000_4108000_VegIndices/'+entry_2017)\n",
    "                index_2018, index_2018_md = raster2array('../../Data/capstone/2018/NEON_D17_SJER_DP3_258000_4108000_VegIndices/'+entry_2018)\n",
    "                \n",
    "                diff_output = index_2017-index_2018\n",
    "                \n",
    "                # save classification results\n",
    "                array2raster('../output/fig/'+entry_2017+'_difference.tif',\n",
    "                             (index_2017_md['extent'][0],index_2017_md['extent'][3]),\n",
    "                             1,-1,\n",
    "                             np.array(diff_output,dtype=float),\n",
    "                             32611)\n",
    "                \n",
    "                #print (entry_2017.split(\"_\"))\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
